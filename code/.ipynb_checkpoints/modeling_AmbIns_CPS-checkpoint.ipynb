{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting data ready to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression,RidgeCV,Lasso,Ridge,LassoCV\n",
    "from sklearn.metrics import r2_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold,train_test_split,cross_val_score\n",
    "from sklearn.linear_model import lars_path\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the dataframe that I built in my scraping notebook\n",
    "with open('schools_updatedData','rb') as read_file:\n",
    "    school_df = pickle.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('schools_finalModelData', 'rb') as read_file:\n",
    "    sch_df6 = pickle.load(read_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Simplify columns and then make dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# This column will be a binary value assigned to unionized charters with contracts \n",
    "# a 1 is a contract with a contract over 200 days old, a 0 is a very new contract/\n",
    "school_df['ThreshContract']=(school_df['Days_Cont']>200)\n",
    "school_df['ThreshContract']=school_df['ThreshContract'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Drop a lot of redundant categorical variable, like CPS network and SQRPrat\n",
    "school_df_smaller=school_df[['SQRPpts', 'Type',\n",
    "       'Ambitious Instruction', 'Collaborative Teachers', 'Effective Leaders',\n",
    "       'Involved Families', 'Supportive Environment',' Total ', 'Bilingual', 'Sped', 'FRLunch', \n",
    "       'Student Attendance Rate', 'Student Mobility Rate',\n",
    "       'Teacher Retention Rate', 'AvgClassSize',\n",
    "       'Principal Turnover within 6 Years', 'ThreshContract','UNIONIZED']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Refine unionized category to be more specific, clean column headings and make everything more intuitive\n",
    "school_df_smaller.UNIONIZED.replace({\"NO\":\"NonUCh\",'YES':'UCh'},inplace=True)\n",
    "school_df_smaller.columns = school_df_smaller.columns.str.strip()\n",
    "school_df_smaller.rename(columns={'Total':'Population'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Get dummy variables for type and unionization statue, drop_first values \n",
    "#to avoid collinearity\n",
    "sch_df= pd.get_dummies(school_df_smaller, drop_first=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Playing around with NaN values\n",
    "\n",
    "For the next few cells, I experiment with different ways of handling NA values - since charters underreport certain data, I don't want to drop NaNs and kick all charters out of my data set. I also don't want to oversmooth my data by plugging in median values for charters all over the place.\n",
    "\n",
    "**NOTE** After dropping NA values, most of the charter schools drop out of the data set, only 5 NonUnionized and 1 Unionized charter remain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sch_df2=sch_df.dropna()\n",
    "sch_df2.UNIONIZED_NonUCh.value_counts(), sch_df2.UNIONIZED_UCh.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Let's run a naive model to see if I can remove features that charters underreport "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y = sch_df2['Ambitious Instruction']\n",
    "x = sch_df2.drop('Ambitious Instruction', axis=1)\n",
    "sch_df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create your model\n",
    "model = sm.OLS(y, x)\n",
    "\n",
    "# Fit your model to your training set\n",
    "fit = model.fit()\n",
    "\n",
    "# Print summary statistics of the model's performance\n",
    "fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Repull Data -> \n",
    "Since Student Mobility, Teacher Retention, Principal Turnover, and Class Size do not have strong impact on that model (and have high NA values for charters), repull the data without those columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Redo all the cleaning I did on previous dataframe, and recreate dummies\n",
    "school_df_smaller=school_df[['SQRPpts', 'Type',\n",
    "       'Ambitious Instruction', 'Collaborative Teachers', 'Effective Leaders',\n",
    "       'Involved Families','Student Attendance Rate', 'Supportive Environment',' Total ', 'Bilingual', 'Sped', 'FRLunch', \n",
    "       'ThreshContract','UNIONIZED']]\n",
    "school_df_smaller.UNIONIZED.replace({\"NO\":\"NonUCh\",'YES':'UCh'},inplace=True)\n",
    "school_df_smaller.columns = school_df_smaller.columns.str.strip()\n",
    "school_df_smaller.rename(columns={'Total':'Population'}, inplace=True)\n",
    "\n",
    "sch_df= pd.get_dummies(school_df_smaller, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### It got a little better - \n",
    "I have 15 charters left in now instead of just 6 (4 unionized, 11 not). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sch_df3=sch_df.dropna()\n",
    "sch_df3.UNIONIZED_UCh.value_counts(),sch_df3.UNIONIZED_NonUCh.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "% Bilingual students and Student Attendace Rate are biased against charters, but I believe will be relevant in my model. They are also not as badly underreported as other features. Since these two features seem to have an impact on the model and are only missing from 10-15% of charters, I will replace them with the median values.\n",
    "\n",
    "With this change made, my dataset keeps 88 charters, approaching the actual number in CPS (107)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Fill NaN entries for %Bilingual and SAR with median values\n",
    "sch_df['Bilingual']=sch_df.Bilingual.fillna(sch_df.Bilingual.median())\n",
    "sch_df['Student Attendance Rate']=sch_df['Student Attendance Rate'].fillna(sch_df['Student Attendance Rate'].median())\n",
    "\n",
    "\n",
    "sch_df4=sch_df.dropna()\n",
    "sch_df4.UNIONIZED_NonUCh.value_counts(),sch_df4.UNIONIZED_UCh.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Let's pickle this dataframe since this is what I will begin using for modeling\n",
    "with open('schools_toModel', 'wb') as to_write:\n",
    "    pickle.dump(sch_df4, to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open('schools_toModel','rb') as read_file:\n",
    "    school_df = pickle.load(read_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Look at correlations\n",
    "Start to think about what features could be thrown out to simplify this model going forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Let's look for correlations between categories - note high correlation between\n",
    "# 'Effective Leaders' and 'Collaborative Teachers', as well as \n",
    "# UnionizedCharters and ThreshContract(definitionally). Notice that Type of school \n",
    "# interfere with each other as well as Student Attendance Rate \n",
    "# (only high schoolers skip school)\n",
    "school_df.corr()\n",
    "sns.heatmap(sch_df.corr(), cmap=\"seismic\", vmin=-1, vmax=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model - Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into 80/20 train and test split.\n",
    "\n",
    "When I ran the model on my training data, I noticed that population had a very high p-value and decided to drop it as a feature. The effect of this was my mean R2 on a K-fold cross-validation went up by 0.005.\n",
    "\n",
    "In addition, 'Collaborative Teachers' shows strong correlation with 'Effective Leaders', so I dropped that to avoid issues with multicollinearity.\n",
    "\n",
    "The ThreshContract column (# of days with contract at unionized charters) is only relevant for 3-4 schools that unionized recently, and had strong correlation with being a unionized charter school in general (duh), so I dropped it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = school_df.drop(['Ambitious Instruction','Population','Collaborative Teachers','ThreshContract'],axis=1), school_df['Ambitious Instruction']\n",
    "\n",
    "X, X_test, y, y_test = train_test_split(X, y, test_size=.2, random_state=15) #hold out 20% of the data for final testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create your model\n",
    "model = sm.OLS(y, X)\n",
    "\n",
    "# Fit your model to your training set\n",
    "fit = model.fit()\n",
    "\n",
    "# Print summary statistics of the model's performance\n",
    "fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this helps with the way kf will generate indices below\n",
    "Xkf, ykf = np.array(X), np.array(y)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state = 4)\n",
    "cross_val_score(lm, Xkf, ykf, cv=kf, scoring='r2').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**High R2train, low R2val**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, my R2-adj is 0.989, but my mean R2 from cross-validiation 0.70. So now it's time to try some regularization, feature engineering, and dropping features.\n",
    "\n",
    "At a first glance, none of my features seem to clearly resemble polynomial functions in relation to 'Ambitious Instruction.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(school_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LARS-PATH - what features can I lose?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First scale your X-values for training and testing data\n",
    "std = StandardScaler()\n",
    "std.fit(X.values)\n",
    "X_tr = std.transform(X.values)\n",
    "X_te = std.transform(X_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas, _, coefs = lars_path(X_tr, y.values, method='lasso')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the LARS path\n",
    "\n",
    "xx = np.sum(np.abs(coefs.T), axis=1)\n",
    "xx /= xx[-1]\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(xx, coefs.T)\n",
    "ymin, ymax = plt.ylim()\n",
    "plt.vlines(xx, ymin, ymax, linestyle='dashed')\n",
    "plt.xlabel('|coef| / max|coef|')\n",
    "plt.ylabel('Coefficients')\n",
    "plt.title('LASSO Path')\n",
    "plt.axis('tight')\n",
    "plt.legend(X.columns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like type of school, and being unionized charters/non/CTU or not. Dropping these can seriously cut down on my dummy variables and clean my models. Let's kill them.\n",
    "\n",
    "I will also drop the variables I saw were not useful and had collinearity issues - population/total and collaborative teachers.\n",
    "\n",
    "I wonder if CTU or not would have been valuable (versus charter). I decide to put that column in and redo the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplify union stuff - just do CTU vs charter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go back and redo building the dataframe, this time ignoring unionization \n",
    "# and just looking at charter vs. not charter\n",
    "# Repeat all cleaning/renaming from beginning\n",
    "trimdummies = school_df_smaller.drop(['Type', 'ThreshContract',' Total ','Collaborative Teachers'],axis=1)\n",
    "trimdummies.UNIONIZED.replace({\"NO\":\"CHARTER\",'YES':'CHARTER'},inplace=True)\n",
    "trimdummies.columns = trimdummies.columns.str.strip()\n",
    "trimdummies.rename(columns={'Total':'Population'}, inplace=True)\n",
    "sch_df= pd.get_dummies(trimdummies, drop_first=True)\n",
    "\n",
    "# Replug in medians for bilingual and SAR\n",
    "sch_df['Bilingual']=sch_df.Bilingual.fillna(sch_df.Bilingual.median())\n",
    "sch_df['Student Attendance Rate']=sch_df['Student Attendance Rate'].fillna(sch_df['Student Attendance Rate'].median())\n",
    "\n",
    "# This dataframe is like before, but no Type and the only dummy variable is CTU/charter\n",
    "sch_df5= sch_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up my training and testing data. Lose Population and CT because I saw earlier they are not useful features\n",
    "X, y = sch_df5.drop(['Ambitious Instruction'],axis=1), sch_df5['Ambitious Instruction']\n",
    "\n",
    "X, X_test, y, y_test = train_test_split(X, y, test_size=.2, random_state=15) #hold out 20% of the data for final testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = StandardScaler()\n",
    "std.fit(X.values)\n",
    "X_tr = std.transform(X.values)\n",
    "X_te = std.transform(X_test.values)\n",
    "alphas, _, coefs = lars_path(X_tr, y.values, method='lasso')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the LARS path\n",
    "\n",
    "xx = np.sum(np.abs(coefs.T), axis=1)\n",
    "xx /= xx[-1]\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(xx, coefs.T)\n",
    "ymin, ymax = plt.ylim()\n",
    "plt.vlines(xx, ymin, ymax, linestyle='dashed')\n",
    "plt.xlabel('|coef| / max|coef|')\n",
    "plt.ylabel('Coefficients')\n",
    "plt.title('LASSO Path')\n",
    "plt.axis('tight')\n",
    "plt.legend(X.columns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I still see the same thing - so being a board of ed school vs. charter drops out first, as well as school type and % SpEd. I decide to drop those features and re-cross-validate. SQRPpts also drops out really early, so let's lose that too. \n",
    "\n",
    "(At this point, I went ahead and did modeling, but then came back and ultimately decided it was best to lose all the ISBE features that were underreported for charters, except the 2 that seem important for my model - %Bilingual and SAR)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplify more - drop the dummies, the factors with underreported data, and other features with low relevance to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rebuild and reclean dataframe, dropping down to NO D\n",
    "sch_df=  school_df_smaller.drop(['Type', 'ThreshContract',' Total ','Sped','SQRPpts','Collaborative Teachers','UNIONIZED','Student Mobility Rate','Teacher Retention Rate','Principal Turnover within 6 Years','AvgClassSize'],axis=1)\n",
    "\n",
    "sch_df['Bilingual']=sch_df.Bilingual.fillna(sch_df.Bilingual.median())\n",
    "sch_df['Student Attendance Rate']=sch_df['Student Attendance Rate'].fillna(sch_df['Student Attendance Rate'].median())\n",
    "sch_df6= sch_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's pickle this dataframe so I don't have to keep recleaning and plugging medians\n",
    "with open('schools_finalModelData', 'wb') as to_write:\n",
    "    pickle.dump(sch_df6, to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redivide my data into a fresh train test split\n",
    "X, y = sch_df6.drop(['Ambitious Instruction'],axis=1), sch_df6['Ambitious Instruction']\n",
    "\n",
    "X, X_test, y, y_test = train_test_split(X, y, test_size=.2, random_state=15) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do my KFolds cross validation on a plain LinearRegression with these 11 features\n",
    "Xkf, ykf = np.array(X), np.array(y)\n",
    "lm=LinearRegression()\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state = 4)\n",
    "cross_val_score(lm, Xkf, ykf, cv=kf, scoring='r2').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these 6 features, a linear regression model has a KFoldsCV R2 of 0.696.\n",
    "\n",
    "This is a lot lower than the training set R2 (0.99). Now I need to start experimenting with other regession types and regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Refinement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try to find the best alpha for Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's find an optimal alpha for my Ridge regression\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state = 4)\n",
    "\n",
    "# Make a list of alphas from 0.01 to 100, and a list to hold R2\n",
    "alphalist = 10**(np.linspace(-2,2,200))\n",
    "R2_list = []\n",
    "\n",
    "#Scale my data\n",
    "std = StandardScaler()\n",
    "std.fit(X.values)\n",
    "X_tr = std.transform(X.values)\n",
    "X_te = std.transform(X_test.values)\n",
    "\n",
    "# Try out every alpha in the list and save the meanCVR2 score\n",
    "for i,curr_alpha in enumerate(alphalist):\n",
    "    lr_model_ridge = Ridge(alpha = curr_alpha)\n",
    "    lr_model_ridge.fit(X_tr, y)\n",
    "    R2_list.append(cross_val_score(lr_model_ridge, X_tr, ykf, cv=kf, scoring='r2').mean())\n",
    "\n",
    "# The best alpha will be the alpha that corresponds to the minimum R2\n",
    "best_alpha = alphalist[R2_list.index(np.max(R2_list))]\n",
    "best_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale my data for training and testing to do a ridge regression\n",
    "std = StandardScaler()\n",
    "std.fit(X.values)\n",
    "X_tr = std.transform(X.values)\n",
    "X_te = std.transform(X_test.values)\n",
    "\n",
    "# Look at my Ridge results and input the best alpha from previous loop\n",
    "lr_model_ridge = Ridge(alpha = 4.5)\n",
    "lr_model_ridge.fit(X_tr, y)\n",
    "\n",
    "list(zip(X.columns, lr_model_ridge.coef_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose between ridge and linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do side by side comparisons of Ridge and Linear for a bunch of different\n",
    "# KFold random states - make sure that Ridge is done on scaled, and linear is on \n",
    "# unscaled data\n",
    "randoms = [10, 42, 4, 15,100]\n",
    "\n",
    "Xkf, ykf = np.array(X_tr), np.array(y)\n",
    "Xkf_lm = np.array(X)\n",
    "\n",
    "print(\"Linear              Ridge\")\n",
    "for seed in randoms:\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state = seed)\n",
    "    print(cross_val_score(lm, Xkf_lm, ykf, cv=kf, scoring='r2').mean(), cross_val_score(lr_model_ridge, Xkf, ykf, cv=kf, scoring='r2').mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying out both linear and ridge regression model seems to always result in a higher CV score for the Ridge model, so let's stick with that.\n",
    "\n",
    "Let's try adding a bunch of polynomial terms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try adding polynomial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature transforms for train, val, and test so that we can run our poly model on each\n",
    "poly = PolynomialFeatures(degree=2) \n",
    "\n",
    "X_train_poly = poly.fit_transform(X_tr)\n",
    "X_test_poly = poly.transform(X_te)\n",
    "\n",
    "# Do a lasso to see which features work as 2nd-degree polynomials\n",
    "lr_model_lasso = Lasso(alpha = 4.5)\n",
    "lr_model_lasso.fit(X_train_poly, y)\n",
    "\n",
    "list(zip(X.columns, lr_model_lasso.coef_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like %bilingual as a 2nd degree polynomial may be a useful term. Let's add that in and rerun the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column with bilingual transformed as a square\n",
    "sch_df6['BilingualSq']= sch_df6['Bilingual']**2\n",
    "X, y = sch_df6.drop(['Ambitious Instruction'],axis=1), sch_df6['Ambitious Instruction']\n",
    "X, X_test, y, y_test = train_test_split(X, y, test_size=.2, random_state=15) \n",
    "\n",
    "# Scale the data for regularization\n",
    "std = StandardScaler()\n",
    "std.fit(X.values)\n",
    "X_tr = std.transform(X.values)\n",
    "X_te = std.transform(X_test.values)\n",
    "\n",
    "# Run another Ridge model\n",
    "lr_model_ridge = Ridge(alpha = 4.5)\n",
    "lr_model_ridge.fit(X_tr, y)\n",
    "\n",
    "# Get a KF-CV score from the new Ridge model\n",
    "Xkf, ykf = np.array(X_tr), np.array(y)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state = 15)\n",
    "cross_val_score(lr_model_ridge, Xkf, ykf, cv=kf, scoring='r2').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, the CV score is higher (0.6966 at RS15) when we DON'T include the BilingualSq column (0.6949 with BSq at RS15), so let's go back to treating all our terms as non-polynomials. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Go back to best model so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column with bilingual transformed as a square\n",
    "X, y = sch_df6.drop(['Ambitious Instruction'],axis=1), sch_df6['Ambitious Instruction']\n",
    "X, X_test, y, y_test = train_test_split(X, y, test_size=.2, random_state=15) \n",
    "\n",
    "# Scale the data for regularization\n",
    "std = StandardScaler()\n",
    "std.fit(X.values)\n",
    "X_tr = std.transform(X.values)\n",
    "X_te = std.transform(X_test.values)\n",
    "\n",
    "# Run another Ridge model\n",
    "lr_model_ridge = Ridge(alpha = 4.5)\n",
    "lr_model_ridge.fit(X_tr, y)\n",
    "\n",
    "# Get a KF-CV score from the new Ridge model\n",
    "Xkf, ykf = np.array(X_tr), np.array(y)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state = 15)\n",
    "cross_val_score(lr_model_ridge, Xkf, ykf, cv=kf, scoring='r2').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing and Calculating Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model_ridge.score(X_te,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import model and fit\n",
    "from sklearn.metrics import mean_squared_error \n",
    "\n",
    "predict = lr_model_ridge.predict(X_te)\n",
    "rmse = np.sqrt(((predict-y_test)**2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Assumptions - Plot Residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resid = sns.scatterplot(x=predict,y=(predict-y_test))\n",
    "resid.set(xlabel='Predicted Ambitious Instruction', ylabel='Residuals')\n",
    "plt.savefig(\"residualsvgpredict.png\",dpi=1200)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make my Q-Q plot to verify that my residuals have a normal distribtuions\n",
    "import scipy.stats as stats\n",
    "res = predict-y_test\n",
    "stats.probplot(res, dist=\"norm\", plot=plt)\n",
    "plt.title(\"Normal Q-Q plot\")\n",
    "plt.savefig(\"QQplotres.png\",dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test out model on a school I know"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the data from my old school, BOYCP\n",
    "X.loc[400053]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make my school's data into an array and scale it, then try \n",
    "# plugging in different values to see what could improve teaching\n",
    "boycp = np.array([40,67,73,0.111,0.957,95.1])\n",
    "boycp = boycp.reshape(1,-1)\n",
    "boycp_tr = std.transform(boycp)\n",
    "lr_model_ridge.predict(boycp_tr.reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This figure is just for my appendix\n",
    "sch_df6.corr()\n",
    "sns.heatmap(sch_df6.corr(),cmap='seismic')\n",
    "plt.tight_layout(pad=0.4, w_pad=0.5, h_pad=1.0)\n",
    "plt.savefig(\"correlations.png\",dpi=600)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
